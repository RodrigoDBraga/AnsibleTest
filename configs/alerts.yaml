groups:
  - name: Server Monitoring
    rules:

    - alert: CPUUsageAlert
      expr: |
        (100 - (avg by(instance) (rate(node_cpu_seconds_total{mode="idle"}[5m])) * 100)) > 70
      for: 5m
      labels:
        severity: '{{ if gt $value 90.0 }}critical{{ else }}warning{{ end }}'
      annotations:
        summary: 'CPU Usage Alert on {{ $labels.instance }}'
        description: 'CPU usage on {{ $labels.instance }} is {{ $value | printf "%.2f" }}% for more than 5 minutes'

    - alert: MemoryUsageAlert
      expr: |
        (node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes) / node_memory_MemTotal_bytes * 100 > 80
      for: 5m
      labels:
        severity: '{{ if gt $value 90.0 }}critical{{ else }}warning{{ end }}'
      annotations:
        summary: 'Memory Usage Alert on {{ $labels.instance }}'
        description: 'Memory usage on {{ $labels.instance }} is {{ $value | printf "%.2f" }}% for more than 5 minutes'

    - alert: DiskSpaceAlert
      expr: |
        100 - ((node_filesystem_avail_bytes{mountpoint="/"} * 100) / node_filesystem_size_bytes{mountpoint="/"}) > 80
      for: 5m
      labels:
        severity: '{{ if gt $value 90.0 }}critical{{ else }}warning{{ end }}'
      annotations:
        summary: 'Disk Space Alert on {{ $labels.instance }}'
        description: 'Disk space usage on {{ $labels.instance }} is {{ $value | printf "%.2f" }}% full'

    - alert: DiskIOAlert
      expr: |
        rate(node_disk_io_time_seconds_total[5m]) * 100 > 80
      for: 5m
      labels:
        severity: '{{ if gt $value 90.0 }}critical{{ else }}warning{{ end }}'
      annotations:
        summary: 'Disk I/O Alert on {{ $labels.instance }}'
        description: 'Disk I/O utilization on {{ $labels.instance }} is {{ $value | printf "%.2f" }}% for more than 5 minutes'

    - alert: NetworkThroughputAlert
      expr: |
        (sum by(instance) (rate(node_network_transmit_bytes_total[5m]) + rate(node_network_receive_bytes_total[5m]))) / node_network_speed_bytes > 0.7
      for: 5m
      labels:
        severity: '{{ if gt $value 0.9 }}critical{{ else }}warning{{ end }}'
      annotations:
        summary: 'Network Throughput Alert on {{ $labels.instance }}'
        description: 'Network throughput on {{ $labels.instance }} is {{ $value | printf "%.2f" }}% of max bandwidth for more than 5 minutes'

    - alert: NetworkErrorRateAlert
      expr: |
        (sum by(instance) (rate(node_network_transmit_errs_total[5m]) + rate(node_network_receive_errs_total[5m]))) / (sum by(instance) (rate(node_network_transmit_packets_total[5m]) + rate(node_network_receive_packets_total[5m]))) > 0.01
      for: 5m
      labels:
        severity: '{{ if gt $value 0.05 }}critical{{ else }}warning{{ end }}'
      annotations:
        summary: 'Network Error Rate Alert on {{ $labels.instance }}'
        description: 'Network error rate on {{ $labels.instance }} is {{ $value | printf "%.2f" }}% for more than 5 minutes'

- alert: ServiceAvailabilityAlert
      expr: |
        avg_over_time(up{job="your_service_job"}[5m]) * 100 < 99
      for: 5m
      labels:
        severity: '{{ if lt $value 95.0 }}critical{{ else }}warning{{ end }}'
      annotations:
        summary: 'Service Availability Alert for {{ $labels.job }} on {{ $labels.instance }}'
        description: 'Service availability for {{ $labels.job }} on {{ $labels.instance }} is {{ $value | printf "%.2f" }}% over the last 5 minutes'

    - alert: ResponseTimeAlert
      expr: |
        histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{job="your_service_job"}[5m])) by (le, instance)) > 2
      for: 5m
      labels:
        severity: '{{ if gt $value 5.0 }}critical{{ else }}warning{{ end }}'
      annotations:
        summary: 'Response Time Alert for {{ $labels.job }} on {{ $labels.instance }}'
        description: '95th percentile response time for {{ $labels.job }} on {{ $labels.instance }} is {{ $value | printf "%.2f" }} seconds over the last 5 minutes'

    - alert: ApplicationErrorRateAlert
      expr: |
        sum(rate(http_requests_total{job="your_service_job",status=~"5.."}[5m])) / sum(rate(http_requests_total{job="your_service_job"}[5m])) > 0.01
      for: 5m
      labels:
        severity: '{{ if gt $value 0.05 }}critical{{ else }}warning{{ end }}'
      annotations:
        summary: 'Application Error Rate Alert for {{ $labels.job }} on {{ $labels.instance }}'
        description: 'Error rate for {{ $labels.job }} on {{ $labels.instance }} is {{ $value | printf "%.2f" }}% of requests over the last 5 minutes'
